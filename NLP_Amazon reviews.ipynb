{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b69c7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Tokenize\n",
    "#2. Remove the stopwords\n",
    "#3. Lemmatization/Stemming\n",
    "#4. Document-Term Matrix -- TfIdf\n",
    "#5. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dcd5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "61231e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score,roc_auc_score,accuracy_score,roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#word_tokenize('An Apple a day keeps the doctor away.So, will I get sick soon?')\n",
    "#tokenizer.tokenize('An Apple a day keeps the doctor away.So, will I get sick soon?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55b52fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite musi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this sound...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>A Book That Is Worth a Second Look: This book...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Best game ever: This games makes even amazing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Guitar in Absentia: With all due respect to a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Stiff and Smells like drying paint: You get w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Review of Pillow: This was a joke. I am sendi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Label\n",
       "0     Stuning even for the non-gamer: This sound tr...      1\n",
       "1     The best soundtrack ever to anything.: I'm re...      1\n",
       "2     Amazing!: This soundtrack is my favorite musi...      1\n",
       "3     Excellent Soundtrack: I truly like this sound...      1\n",
       "4     Remember, Pull Your Jaw Off The Floor After H...      1\n",
       "..                                                 ...    ...\n",
       "194   A Book That Is Worth a Second Look: This book...      1\n",
       "195   Best game ever: This games makes even amazing...      1\n",
       "196   Guitar in Absentia: With all due respect to a...      0\n",
       "197   Stiff and Smells like drying paint: You get w...      0\n",
       "198   Review of Pillow: This was a joke. I am sendi...      0\n",
       "\n",
       "[199 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df=pd.read_csv('Amazon_Reviews.csv')\n",
    "\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "228f1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=reviews_df['Label']\n",
    "\n",
    "reviews_df.drop(columns='Label',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "002958f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(reviews_df,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ee7495d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=RegexpTokenizer(r'\\w+')\n",
    "en_sw=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8a73cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "tfidf=TfidfVectorizer()\n",
    "\n",
    "#stemmer.stem('cacti')\n",
    "#lemmatizer.lemmatize('playing',pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8e908f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    tokens=tokenizer.tokenize(text)\n",
    "    pure_tokens=[token.lower() for token in tokens if token.lower() not in en_sw]\n",
    "    lemmatized_tokens=[lemmatizer.lemmatize(token,pos='v') for token in pure_tokens]\n",
    "    \n",
    "    return lemmatized_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "945745a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183    [handful, track, hear, far, complete, though, ...\n",
       "38     [work, mac, clearly, say, line, work, mac, os,...\n",
       "24     [like, album, think, would, hear, song, two, t...\n",
       "142    [pattern, detail, sketch, although, excite, pu...\n",
       "141    [contemporary, fairytale, sure, delight, book,...\n",
       "                             ...                        \n",
       "106    [authentic, first, encounter, yoruba, say, cds...\n",
       "14     [awful, beyond, belief, feel, write, keep, oth...\n",
       "92     [omg, soulwax, own, wow, like, amaze, album, e...\n",
       "179    [yet, another, unsubstantiated, case, believe,...\n",
       "102    [yes, get, book, expect, much, man, wrong, lov...\n",
       "Name: Review, Length: 159, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Review']=X_train['Review'].apply(text_preprocessing)\n",
    "X_test['Review']=X_test['Review'].apply(text_preprocessing)\n",
    "\n",
    "\n",
    "X_train['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "28de35b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-34332703f8fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_tfidf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_tfidf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \"\"\"\n\u001b[0;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1204\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "train_tfidf=tfidf.fit_transform(X_train['Review'])\n",
    "test_tfidf=tfidf.transform(X_test['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb=MultinomialNB()\n",
    "mnb.fit(train_tfidf,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50176a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_pred=mnb.predict(test_tfidf)\n",
    "pos_probabs=mnb.predict_proba(test_tfidf)[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d22268",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,mnb_pred)\n",
    "recall_score(y_test,mnb_pred)\n",
    "precision_score(y_test,mnb_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,thresholds=roc_curve(y_test,pos_probabs)\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "roc_auc_score(y_test,pos_probabs)\n",
    "\n",
    "accuracy_score(y_test,mnb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6570b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de18cf",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "39e7a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0d256cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6021, 33260)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Word2Vec(window=4,min_count=9,workers=4,vector_size=32)\n",
    "\n",
    "model.build_vocab(X_train['Review'],progress_per=1000)\n",
    "\n",
    "model.train(X_train['Review'],total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7f2ac8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183    [handful, track, hear, far, complete, though, ...\n",
       "38     [work, mac, clearly, say, line, work, mac, os,...\n",
       "24     [like, album, think, would, hear, song, two, t...\n",
       "142    [pattern, detail, sketch, although, excite, pu...\n",
       "141    [contemporary, fairytale, sure, delight, book,...\n",
       "                             ...                        \n",
       "106    [authentic, first, encounter, yoruba, say, cds...\n",
       "14     [awful, beyond, belief, feel, write, keep, oth...\n",
       "92     [omg, soulwax, own, wow, like, amaze, album, e...\n",
       "179    [yet, another, unsubstantiated, case, believe,...\n",
       "102    [yes, get, book, expect, much, man, wrong, lov...\n",
       "Name: Review, Length: 159, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "33317261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02859885, -0.02536807, -0.01462234, -0.00569853,  0.000606  ,\n",
       "       -0.018159  ,  0.00353976,  0.00629209, -0.01277917,  0.00869157,\n",
       "        0.04178849, -0.00488488,  0.0197595 , -0.03911533,  0.03152749,\n",
       "       -0.00958504,  0.0395254 ,  0.0123668 ,  0.00836818, -0.02245821,\n",
       "       -0.01476104,  0.05614202,  0.01510634,  0.01341541,  0.02258139,\n",
       "        0.00502274,  0.01135106,  0.00538107, -0.02550888, -0.03846185,\n",
       "       -0.01234535, -0.02359255], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('soundtrack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c1563c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183    [handful, track, hear, far, complete, though, ...\n",
       "38     [work, mac, clearly, say, line, work, mac, os,...\n",
       "24     [like, album, think, would, hear, song, two, t...\n",
       "142    [pattern, detail, sketch, although, excite, pu...\n",
       "141    [contemporary, fairytale, sure, delight, book,...\n",
       "                             ...                        \n",
       "106    [authentic, first, encounter, yoruba, say, cds...\n",
       "14     [awful, beyond, belief, feel, write, keep, oth...\n",
       "92     [omg, soulwax, own, wow, like, amaze, album, e...\n",
       "179    [yet, another, unsubstantiated, case, believe,...\n",
       "102    [yes, get, book, expect, much, man, wrong, lov...\n",
       "Name: Review, Length: 159, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Review']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
